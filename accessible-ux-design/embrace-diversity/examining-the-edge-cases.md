# Examining the edge cases

## Designing for the statistical normal distribution of users

If you always design for the "typical" or "statistical normal" user, you're missing the chance to invent solutions that reach even more people. Before we go too far, let's talk about the actual meaning of the word "normal."

Normal, when used as a technical term in mathematics, refers to statistical probability. It describes the likelihood that a member of a given population will have characteristics that match the mathematical average of the population as a whole. 

It is represented visually by a graphical curve, often called a "bell curve" because the shape looks somewhat like a bell with a rounded top and flared edges at the bottom. 

If you target your design at the users who fall in the middle of the normal curve (in statistical terms, we would say plus or minus one standard deviation from the mean, or average), you would meet the needs of 68% of the users. 

That's a substantial majority. You might think that's good enough. For the majority of your users it is in fact good enough. But it's not good enough for 32% of your users.

## Designing for the edge cases

- Different approach: design for the edge cases
- you would meet the needs of two very different kinds of people
- your design would have to take into account the middle ground between them
- you'd end up satisfying the needs of 95% to 99.7% of the users.

Designing for the edge cases requires more skill and planning than designing only for the normal user.
The rewards are also greater for a larger number of people.

We're going to take this challenge to heart and assign ourselves the task of designing video games for people at two very different points along the ability spectrum:

- People who are blind
- People with limited mobility

## Challenge: Video games for people who are blind

Imagine you are given the task of designing online video games for people who are completely blind. They can't see the screen at all, so you don't have to make it look good. In fact, you don't need a graphic user interface at all.

Input: Typically, people who are blind use keyboards to input information into the computer. With video games, you have some room for additional creativity. Are there ways of making other input devices — like a mouse, a joystick, a game controller, a motion detection device, a voice recognition device, etc. — work for people who are blind?

Output: They're going to be using a screen reader to hear the output of the game. They'll also be able to hear the audio of the game itself. They won't be able to see the screen, so everything will have to be available through audio, or, if you get more creative, perhaps through tactile feedback.

### Questions to consider

- How would you approach this design challenge?
- What kinds of assumptions will you need to discard to make this project a success?
- Which kinds of interactions would be easy to make work for people who are blind? Which types would be most difficult?
- Are there some types of interactions that would be impossible?
- If you design a video game primarily for people who are blind, would it also work for people who can see?

## Challenge: Video games for people with limited mobility

Now let's consider a different group of people: people who cannot use their hands well enough to use standard video game interfaces. Perhaps they cannot use their hands at all, or perhaps they have tremors in their hands, limiting their precision, or perhaps they lack grip strength and the ability to move quickly. There are many variations in human mobility.

Input: There are a wide variety of input methods for people with motor disabilites:

- Eye-gaze tracking devices that allow users to point and select with their eyes
- Single-switch devices that allow users to push a single button to interact with an on-screen keyboard and on-screen menus of context-sensitive options
- Sip and puff devices that allow people to use their breath to control an on-screen keyboard and on-screen menus of context-sensitive options
- Voice recognition software that allows users to select items on the screen (by their label or ID) and interact with them via context-sensitive menus and commands
- A mouth stick (a stick with rubber tips on both ends) to type and use a trackball mouse

Output: Assuming the person does not have multiple disabilities, the output would be the visual and audio output that people with sight and hearing would expect. There are no special output considerations for this use case.

### Questions to consider

- How much overlap is there between the needs of a person who is blind and a person with limited mobility when playing video games?
- If you completely solve the challenge for one group, how relevant are those solutions to the other group?
- If you solve the challenges only for these two use cases and completely ignore users without disabilities, how much overlap is there? Do these two use cases cover all the needs, or will you need a third use case for people without disabilities?
